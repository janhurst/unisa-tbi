{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bitcapstoneconda95c7eaee4aa645f6a7eec5cde52f040b",
   "display_name": "Python 3.8.1 64-bit ('capstone': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "START: 00-load-raw-data.ipynb\n  PECARN TBI data read from c:\\Jan\\Capstone\\data/TBI PUD 10-08-2013.csv into \"pecarn_tbi\" dataframe\nSTART: 01-data-cleaning.ipynb\n"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# call the 00-load-raw-data notebook to bring the pecarn_tbi dataframe into the environment\n",
    "%run 00-load-raw-data.ipynb\n",
    "\n",
    "print(\"START: 01-data-cleaning.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "AMS            category\nAMSAgitated    category\nAMSOth         category\nAMSRepeat      category\nAMSSleep       category\n                 ...   \nSeizOccur      category\nVomit          category\nVomitLast      category\nVomitNbr       category\nVomitStart     category\nLength: 124, dtype: object"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "pecarn_tbi.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pecarn_tbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glasgow Coma Score (GCS)\n",
    "- drop records where *GCSTotal* is less than 14\n",
    "- drop *GCSGroup* as redundant"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dropping records where GCS < 14\n  Dropping GCS columns as they are now redundant\n"
    }
   ],
   "source": [
    "print(\"  Dropping records where GCS < 14\")\n",
    "data = data[data['GCSGroup'] == 2]\n",
    "\n",
    "print(\"  Dropping GCS columns as they are now redundant\")\n",
    "data = data.drop(columns=['GCSGroup', 'GCSTotal', 'GCSEye', 'GCSVerbal', 'GCSMotor'])\n",
    "\n",
    "#print(\"  Dropping GCSGroup as it is now redundant\")\n",
    "#data = data.drop(columns='GCSGroup')\n",
    "\n",
    "# print(\"  Filling missing GCSEye, GCSVerbal, GCSMotor when GCSTotal is 15\")\n",
    "# gcs_fill = data['GCSTotal'].eq(15) & (data['GCSEye'].isna() | data['GCSVerbal'].isna() | data['GCSMotor'].isna())\n",
    "# data.loc[gcs_fill, 'GCSEye'] = 4\n",
    "# data.loc[gcs_fill, 'GCSVerbal'] = 5\n",
    "# data.loc[gcs_fill, 'GCSMotor'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age\n",
    " - drop one of *AgeInMonth* or *AgeinYears* as they are effectively the same\n",
    " - rename *AgeinYears* to *Age*\n",
    " - remove the *AgeTwoPlus* category, this is something that a machine learning algorithm should learn"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dropping AgeInMonth\n  Renaming AgeinYears to Age\n"
    }
   ],
   "source": [
    "print(\"  Dropping AgeInMonth\")\n",
    "data = data.drop(columns='AgeInMonth')\n",
    "    \n",
    "print(\"  Renaming AgeinYears to Age\")\n",
    "data.rename(columns={'AgeinYears': 'Age'}, inplace=True)\n",
    "\n",
    "#print(\"  Dropping AgeTwoPlus\")\n",
    "#data = data.drop(columns='AgeTwoPlus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employee Type and Certification\n",
    "- drop *EmplType* and *Certification* as not relevant (?)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dropping EmplType\n  Dropping AgeInMonth\n"
    }
   ],
   "source": [
    "print(\"  Dropping EmplType\")\n",
    "data = data.drop(columns='EmplType')\n",
    "\n",
    "print(\"  Dropping AgeInMonth\")\n",
    "data = data.drop(columns='Certification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Injury Mechanism\n",
    "- drop *High_impact_InjSev* as the information is encoded in *InjuryMech*\n",
    "- TODO consider filtering out *High_impact_InjSev*=1"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dropping High_impact_InjSev\n  Renaming InjuryMech to Injury_Mechanism\n"
    }
   ],
   "source": [
    "print(\"  Dropping High_impact_InjSev\")\n",
    "data = data.drop(columns='High_impact_InjSev')\n",
    "\n",
    "print(\"  Renaming InjuryMech to Injury_Mechanism\")\n",
    "data.rename(columns={'InjuryMech': 'Injury_Mechanism'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acting Normal\n",
    "- rename *ActNorm* to *Acting_Normal*\n",
    "- where *ActNorm* is NaN assume that if it was of note it would have been answered as \"No\", and thus missing data can be set to \"Yes\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Renaming ActNorm to Acting_Normal\n  Setting Acting_Normal missing data to 1 (Yes)\n"
    }
   ],
   "source": [
    "print(\"  Renaming ActNorm to Acting_Normal\")\n",
    "data.rename(columns={'ActNorm': 'Acting_Normal'}, inplace=True)\n",
    "\n",
    "print(\"  Setting Acting_Normal missing data to 1 (Yes)\")\n",
    "data.loc[data['Acting_Normal'].isna(), 'Acting_Normal'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings\n",
    "- drop Finding## columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Dropping Findings## columns\n"
    }
   ],
   "source": [
    "print(\"  Dropping Findings## columns\")\n",
    "data = data.drop(columns=[col for col in list(data.columns) if col.startswith('Finding')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Column Ordering"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reindex(sorted(data.columns), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The cleaned dataset is now available in a dataframe named \"data\"\n"
    }
   ],
   "source": [
    "print('  The cleaned dataset is now available in a dataframe named \"data\"')"
   ]
  }
 ]
}